{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "aman_discriminant_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "d1jvXBfCDRqN"
      },
      "source": [
        "# DISCRIMINANT ANALYSIS\n",
        "\n",
        "In this coding assignment you are to implement a Minimum Risk Bayes Decision Theoretic classifier and use it to classify the test examples in the provided datasets.  \n",
        "Assume the following:\n",
        "1. All conditional density functions are multivariate Gaussian\n",
        "2. Each class has its own covariance matrix\n",
        "3. Equally likely prior probabilities\n",
        "4. 0-1 loss function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-qRoESDRqP"
      },
      "source": [
        "## Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHO3CyvyrqUI",
        "outputId": "e4f53c80-27ef-4c60-83cd-7e681dc09419"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3TJafk1rzNp"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/Data/bayes-classifier/iris_corrupted_training_data.csv'\n",
        "test_path = '/content/drive/MyDrive/Data/bayes-classifier/iris_validation_data.csv'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5tFsCiqDRqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2923ee5-1459-4cd7-c71d-f6e78ce917e6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training data - 135 observations, 4 features, 3 classes, \n",
        "df = pd.read_csv(train_path)\n",
        "print(df.head())\n",
        "df = df.values\n",
        "tr_data = df\n",
        "\n",
        "# Load validation data - 15 samples\n",
        "df = pd.read_csv(test_path)\n",
        "print(df.head())\n",
        "df = df.values\n",
        "val_data = df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0        5.7147        2.6743         3.2696       1.65440       2\n",
            "1        5.1734        3.7374         5.9442       3.00050       3\n",
            "2        7.3776        3.1505         3.3543       0.64839       2\n",
            "3        6.4908        2.3983         3.3917       1.54950       2\n",
            "4        6.8182        3.4016         4.7495       0.57970       3\n",
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0           4.4           2.9            1.4           0.2       1\n",
            "1           6.7           3.0            5.2           2.3       3\n",
            "2           4.9           3.1            1.5           0.2       1\n",
            "3           5.1           2.5            3.0           1.1       2\n",
            "4           6.1           3.0            4.6           1.4       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbgINl8MDRqc"
      },
      "source": [
        "# Compute various components of the disriminant functions\n",
        "tr_data1 = tr_data[np.where(tr_data[:,4]==1),:]  # shape = 1,45,5\n",
        "tr_data2 = tr_data[np.where(tr_data[:,4]==2),:]\n",
        "tr_data3 = tr_data[np.where(tr_data[:,4]==3),:]\n",
        "[i,j,k] = np.shape(tr_data1)\n",
        "\n",
        "tr_data1 = tr_data1.reshape(j,k)  # reshape to 2D (45,5), last col is label col\n",
        "tr_data2 = tr_data2.reshape(j,k)\n",
        "tr_data3 = tr_data3.reshape(j,k)\n",
        "\n",
        "# Size of tr_data* are now 45x4\n",
        "tr_data1 = tr_data1[:,0:4]\n",
        "tr_data2 = tr_data2[:,0:4]\n",
        "tr_data3 = tr_data3[:,0:4]\n",
        "\n",
        "# TO DO: \n",
        "# Find the mean of each class\n",
        "#  u1, u2, u3 are the 1x4 mean vectors for tr_data1, tr_data2, tr_data3 matrices\n",
        "#  Note: dimension of each of tr_data is 45x4, \n",
        "#        hence dimensions of u1, u2, u3 = 1x4\n",
        "# Hint: use np.mean\n",
        "\n",
        "u1,u2,u3 = [],[],[]\n",
        "\n",
        "\n",
        "for i in range(np.shape(tr_data1)[1]):\n",
        "    u1.append(np.mean(tr_data1[:,i]))\n",
        "    u2.append(np.mean(tr_data2[:,i]))\n",
        "    u3.append(np.mean(tr_data3[:,i]))\n",
        "\n",
        "# TO DO:\n",
        "# Find the covariance of each class\n",
        "#  cov1, cov2, cov3 are the covariance matrices of \n",
        "#      tr_data1, tr_data2, tr_data3\n",
        "#  dimension cov1, cov2, cov3 must be 4x4\n",
        "# Hint: use np.cov, np.tranpose\n",
        "cov1 = np.cov(np.transpose(tr_data1))\n",
        "cov2 = np.cov(np.transpose(tr_data2))\n",
        "cov3 = np.cov(np.transpose(tr_data3))\n",
        "\n",
        "# TO DO: \n",
        "# Compute the determinant of cov* and its log. These are scalar quantities\n",
        "#  Hint: use np.log, np.linalg.det\n",
        "\n",
        "D1 = np.linalg.det(cov1)\n",
        "D2 = np.linalg.det(cov2)\n",
        "D3 = np.linalg.det(cov3)\n",
        "l1 = np.log(D1)\n",
        "l2 = np.log(D2)\n",
        "l3 = np.log(D3)\n",
        "\n",
        "# TO DO:\n",
        "# Compute the inverse of cov*\n",
        "#   These are matrices of size 4x4\n",
        "#   Hint: use np.linalg.inv\n",
        "\n",
        "I1 = np.linalg.inv(cov1)\n",
        "I2 = np.linalg.inv(cov2)\n",
        "I3 = np.linalg.inv(cov3)\n",
        "\n",
        "# Equally likely proir prob.\n",
        "log_prior = np.log(1/3)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLRWIp4_K2Rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d689bccd-ebfc-42bc-a6bc-73c78a97e6e9"
      },
      "source": [
        "# print the mean vectors and the covariance matrices\n",
        "print(u1)\n",
        "print(u2)\n",
        "print(u3)\n",
        "print(cov1)\n",
        "print(cov2)\n",
        "print(cov3)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.800817777777778, 3.4879955555555555, 1.2692098888888892, 0.34787733333333337]\n",
            "[6.065882222222222, 2.8228797777777777, 4.262413333333333, 1.1078519666666666]\n",
            "[6.42966, 2.956569555555556, 5.558746666666666, 1.9247654666666667]\n",
            "[[ 0.73847372 -0.09788292  0.162097    0.09430334]\n",
            " [-0.09788292  1.04517177  0.08250472  0.06122466]\n",
            " [ 0.162097    0.08250472  0.75386746  0.07747734]\n",
            " [ 0.09430334  0.06122466  0.07747734  0.51347455]]\n",
            "[[ 1.02666705  0.16051089  0.28736137 -0.10850815]\n",
            " [ 0.16051089  0.80414317  0.20221368 -0.07318826]\n",
            " [ 0.28736137  0.20221368  0.74048204 -0.04380217]\n",
            " [-0.10850815 -0.07318826 -0.04380217  0.69674064]]\n",
            "[[1.36272732 0.26608677 0.44568822 0.30336696]\n",
            " [0.26608677 1.03934606 0.12853287 0.18437967]\n",
            " [0.44568822 0.12853287 0.69605886 0.23021863]\n",
            " [0.30336696 0.18437967 0.23021863 0.85756954]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ab1rXfDRqi"
      },
      "source": [
        "## Validation phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1zwqD6DRqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76758941-8aef-494e-bb34-6186fb571b05"
      },
      "source": [
        "# Evaluate model accuracy with validation dataset\n",
        "# The dimension of the validation dataset, val_data, is 15x5. The first four\n",
        "# columns are the feature columns and the last column is the class label column\n",
        "\n",
        "# For each sample, compute the discriminant function (g1, g2, g3) corresponding to each class\n",
        "# Assume equal prior = 1/3\n",
        "# The predicted class label is associated with the largest of g1, g2, g3\n",
        "# Count the number of correctly predicted labels\n",
        "\n",
        "correct_class = 0;  # number of correctly predicted label\n",
        "\n",
        "for i in range(0, len(val_data)):\n",
        "    \n",
        "    x = val_data[i,0:4]  # test sample's feature vector (transpose) 1x4\n",
        "    y = val_data[i,4]    # test samples's true label\n",
        "    \n",
        "    # TO DO: compute g1, g2, g3\n",
        "    g1 = - (0.5)* np.dot(np.dot(np.transpose(x-u1),inv1),(x-u1)) - (0.5)*l1 + log_prior\n",
        "    g2 = - (0.5)* np.dot(np.dot(np.transpose(x-u2),inv2),(x-u2)) - (0.5)*l2 + log_prior\n",
        "    g3 = - (0.5)* np.dot(np.dot(np.transpose(x-u3),inv3),(x-u3)) - (0.5)*l3 + log_prior\n",
        "\n",
        "\n",
        "\n",
        "    # TO DO: \n",
        "    #  Now find the predicted class y_hat, compare it with the true label y\n",
        "    #  and count the number of corectly predicted labels (correct_class)\n",
        "    #  Recall this is a classification problem, hence y_hat should be \n",
        "    #  a discrete value (1, 2 or 3)\n",
        "    g = [g1,g2,g3]\n",
        "    if(max(g)==g1):\n",
        "        yhat=1\n",
        "    elif(max(g)==g2):\n",
        "        yhat = 2\n",
        "    else:\n",
        "        yhat=3\n",
        "    \n",
        "    if (yhat == y):\n",
        "        correct_class = correct_class + 1;\n",
        "\n",
        "print('Classification accuracy = ', '{0:.4f}'. format(correct_class/15))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification accuracy =  0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_xJ76dPXcgc"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}